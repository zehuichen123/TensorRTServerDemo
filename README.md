## Triton Inference Server with Flask

### Intro

This is a demo for Triton Inference Server with full backend support.

### Usage

```shell
# start triton inference service
cd demo_model
source start_triton.sh
# start backend service
cd deep_server
source run.sh
```
